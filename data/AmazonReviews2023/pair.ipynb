{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/home/xingmei/.conda/envs/rec/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix, save_npz, load_npz\n",
    "from multiprocessing import Pool, Manager, Value\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../../RecStudio')\n",
    "import pickle\n",
    "import numpy as np\n",
    "from data.MIND.process import MINDSeqDataset\n",
    "from dataset import CTRDataset\n",
    "from typing import Dict\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "MAX_LEN = 256 #512\n",
    "MODEL_ID = '../../mxbai-embed-large-v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grocery_and_Gourmet_Food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Grocery_and_Gourmet_Food'\n",
    "# ----------------------------------------Filter pairs-----------------------------------------------\n",
    "if not 'co_occurrence' in locals().keys():\n",
    "    co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "    co_occurrence = co_occurrence.tocoo()\n",
    "if not 'sim' in locals().keys():\n",
    "    sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sim) # 88,601,340\n",
    "len([_ for _ in sim if _ > 0.65]) # 4,767,776\n",
    "len([_ for _ in sim if _ > 0.8]) # 414,030\n",
    "len([_ for _ in sim if _ > 0.9]) # 82,072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([_ for _ in co_occurrence.data if _ > 0.1]) # 6,411,474\n",
    "len([_ for _ in co_occurrence.data if _ > 0.3]) # 40,732\n",
    "len([_ for _ in co_occurrence.data if _ > 0.5]) # 904\n",
    "len([_ for k, _ in enumerate(co_occurrence.data) if _ > 0.3 and \\\n",
    "                                                (co_occurrence.row[k] != co_occurrence.col[k])]) # 40,732"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [00:27<00:00, 3276150.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 41036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "COS_SIM_THRESHOLD = 0.9\n",
    "\n",
    "pairs_9 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if  sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_9 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_9.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "\n",
    "print(f\"Length of pairs: {len(pairs_9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [00:27<00:00, 3215902.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.3\n",
    "COS_SIM_THRESHOLD = 0.7\n",
    "\n",
    "pairs_37 = []\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_37 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_37.append((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "\n",
    "print(f\"Length of pairs: {len(pairs_37)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_37, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [00:27<00:00, 3183431.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 5207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.8\n",
    "\n",
    "pairs_28 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_28 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_28.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "\n",
    "print(f\"Length of pairs: {len(pairs_28)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [00:27<00:00, 3176807.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 31323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.1\n",
    "COS_SIM_THRESHOLD = 0.8\n",
    "\n",
    "pairs_18 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_18 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_18.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "\n",
    "print(f\"Length of pairs: {len(pairs_18)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [00:27<00:00, 3168787.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 9236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.1\n",
    "COS_SIM_THRESHOLD = 0.9\n",
    "\n",
    "pairs_19 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_19 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_19.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "\n",
    "print(f\"Length of pairs: {len(pairs_19)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'pairs/{category}_2_8.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_28, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'pairs/{category}_1_9.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_19, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [00:57<00:00, 1543446.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 20366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.3\n",
    "pairs = []\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs.append((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [22:05<00:00, 66849.94it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 187569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "pairs = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [00:40<00:00, 2180320.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 11801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.7\n",
    "pairs_27 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_27 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_27.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_27)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 246006/88601340 [00:00<00:35, 2459786.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88601340/88601340 [00:29<00:00, 2959751.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 21716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_265, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3102285714285714\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_265:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "avg_cnt = 0\n",
    "for i in range(1, 140000):\n",
    "    avg_cnt += item_cnt.get(i, 0)\n",
    "avg_cnt /= 140000\n",
    "print(avg_cnt)\n",
    "\n",
    "item_cnt_lst = [item_cnt.get(i, 0) for i in range(1, 140000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist([_ for _ in item_cnt_lst if _ < 10 and _ > 0], bins=10, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([i for i in range(1, 140000) if i not in item_cnt])) # 125,483\n",
    "len(item_cnt.keys()) # 14,516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38411"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_9:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "len(item_cnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3720"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_37:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "len(item_cnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7502"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_28:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "len(item_cnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14516"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_265:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "len(item_cnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14516/14516 [01:45<00:00, 137.15it/s] \n"
     ]
    }
   ],
   "source": [
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "if not 'guide_model_text_embedding' in locals().keys():\n",
    "    guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.5027"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDs_and_Vinyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'CDs_and_Vinyl'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70245054/70245054 [00:24<00:00, 2832228.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 32008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_265, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70245054/70245054 [00:23<00:00, 3016591.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 19962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.7\n",
    "pairs_27 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_27 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_27.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_27)}\")\n",
    "with open(f'pairs/{category}_27.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_27, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26148/26148 [05:41<00:00, 76.55it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4426, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_265:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.4426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19546/19546 [03:09<00:00, 102.99it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4435, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_27:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.4435"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221214226/221214226 [01:09<00:00, 3182753.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 8664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "category = 'Electronics'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_265, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10861/10861 [01:00<00:00, 180.61it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4709, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_265:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.4709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kindle_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Kindle_Store'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1489476238/1489476238 [08:29<00:00, 2922688.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 2919321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1489476238/1489476238 [08:00<00:00, 3102919.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 292755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.3\n",
    "COS_SIM_THRESHOLD = 0.8\n",
    "pairs_38 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_38 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_38.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_38)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1489476238/1489476238 [08:11<00:00, 3029533.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 26114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.4\n",
    "COS_SIM_THRESHOLD = 0.9\n",
    "pairs_49 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_49 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_49.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_49)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_49, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1489476238/1489476238 [08:19<00:00, 2980004.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 15397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.5\n",
    "COS_SIM_THRESHOLD = 0.9\n",
    "pairs_59 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_59 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_59.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_59)}\")\n",
    "\n",
    "with open(f'pairs/{category}_59.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_59, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16739/16739 [02:37<00:00, 106.55it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5811, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_59:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.5811"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothing_Shoes_and_Jewelry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Clothing_Shoes_and_Jewelry'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379564110/379564110 [02:06<00:00, 3009388.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 17211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.75\n",
    "pairs_275 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_275 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_275.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_275)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_275, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17976/17976 [02:41<00:00, 111.33it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5134, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_275:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Health_and_Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Health_and_Household'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))\n",
    "\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")\n",
    "# 100%|██████████| 151069450/151069450 [01:48<00:00, 1388747.61it/s]\n",
    "# Length of pairs: 56631\n",
    "\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.75\n",
    "pairs_275 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_275 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_275.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_275)}\")\n",
    "# 100%|██████████| 151069450/151069450 [01:35<00:00, 1582510.79it/s]\n",
    "# Length of pairs: 19236\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_275, f)\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_275:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.4899\n",
    "\n",
    "# 100%|██████████| 12953/12953 [01:07<00:00, 190.60it/s] \n",
    "# tensor(0.4899, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies_and_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Movies_and_TV'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")\n",
    "# 100%|██████████| 264980832/264980832 [03:02<00:00, 1449614.89it/s]\n",
    "# Length of pairs: 89280\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.8\n",
    "pairs_28 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_28 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_28.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_28)}\")\n",
    "# 100%|██████████| 264980832/264980832 [03:01<00:00, 1463827.76it/s]\n",
    "# Length of pairs: 55040\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.3\n",
    "COS_SIM_THRESHOLD = 0.8\n",
    "pairs_38 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_38 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_38.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_38)}\")\n",
    "# 100%|██████████| 264980832/264980832 [02:46<00:00, 1589757.96it/s]\n",
    "# Length of pairs: 20212\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_38, f)\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_38:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.4949\n",
    "\n",
    "# 100%|██████████| 18196/18196 [02:23<00:00, 126.87it/s] \n",
    "# tensor(0.4949, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pet_Supplies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Pet_Supplies'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")\n",
    "# 0%|          | 0/60342046 [00:00<?, ?it/s]\n",
    "# 100%|██████████| 60342046/60342046 [00:34<00:00, 1764988.17it/s]\n",
    "# Length of pairs: 854\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_265, f)\n",
    "\n",
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_265:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.5004\n",
    "# 100%|██████████| 7939/7939 [00:28<00:00, 273.94it/s] \n",
    "# tensor(0.5004, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Software'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")\n",
    "#   2%|▏         | 153030/7488958 [00:00<00:04, 1530239.44it/s]\n",
    "# 100%|██████████| 7488958/7488958 [00:04<00:00, 1521306.30it/s]\n",
    "# Length of pairs: 4336\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_265, f)\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_265:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.4403\n",
    "\n",
    "# 100%|██████████| 3437/3437 [00:04<00:00, 703.33it/s] \n",
    "# tensor(0.4403, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home_and_Kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Home_and_Kitchen'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.3\n",
    "COS_SIM_THRESHOLD = 0.9\n",
    "pairs_39 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_39 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_39.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_39)}\")\n",
    "# 100%|██████████| 520756772/520756772 [06:06<00:00, 1422714.58it/s]\n",
    "# Length of pairs: 1477\n",
    "\n",
    "CO_OCCURENCE_THRESHOLD = 0.3\n",
    "COS_SIM_THRESHOLD = 0.8\n",
    "pairs_38 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_38 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_38.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_38)}\")\n",
    "# 54%|█████▎    | 278898748/520756772 [03:13<02:45, 1462273.93it/s]IOStream.flush timed out\n",
    "# 100%|██████████| 520756772/520756772 [06:55<00:00, 1253529.14it/s]\n",
    "# Length of pairs: 3357\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_38, f)\n",
    "\n",
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_38:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim\n",
    "# 100%|██████████| 5178/5178 [00:07<00:00, 677.32it/s] \n",
    "# tensor(0.4368, device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
