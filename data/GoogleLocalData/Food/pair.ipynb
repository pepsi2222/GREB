{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix, save_npz, load_npz\n",
    "from multiprocessing import Pool, Manager, Value\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "work_dir = re.search('(.*GRE).*', os.getcwd(), re.IGNORECASE).group(1)\n",
    "sys.path.append(work_dir)\n",
    "sys.path.append(os.path.join(work_dir, 'RecStudio'))\n",
    "import pickle\n",
    "import numpy as np\n",
    "from data.MIND.process import MINDSeqDataset\n",
    "from dataset import CTRDataset\n",
    "from typing import Dict\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "MAX_LEN = 512\n",
    "MODEL_ID = '../../../mxbai-embed-large-v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alabama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Alabama'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([_ for _ in co_occurrence.data if _ > 0.1]) # 180948\n",
    "len([_ for _ in co_occurrence.data if _ > 0.2]) # 16269\n",
    "len([_ for _ in co_occurrence.data if _ > 0.3]) # 1681\n",
    "\n",
    "len(sim)                          # 17017658\n",
    "len([_ for _ in sim if _ > 0.65]) # 7781158\n",
    "len([_ for _ in sim if _ > 0.8])  # 421828\n",
    "len([_ for _ in sim if _ > 0.9])  # 67536\n",
    "len([_ for _ in sim if _ > 0.95]) # 4098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:07<00:00, 2192644.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 3956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.7\n",
    "pairs_27 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_27 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_27.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_27)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_27, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:08<00:00, 2118431.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 8121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "\n",
    "pairs_2 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_2 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_2.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "\n",
    "print(f\"Length of pairs: {len(pairs_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:07<00:00, 2141524.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 25919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.15\n",
    "\n",
    "pairs_2 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_2 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_2.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "\n",
    "print(f\"Length of pairs: {len(pairs_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:07<00:00, 2267148.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 6221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:07<00:00, 2145714.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.3\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_365 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_365 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_365.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_365)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17017658 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:05<00:00, 3300908.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.3\n",
    "COS_SIM_THRESHOLD = 0.7\n",
    "pairs_37 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_37 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_37.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_37)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_37, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:05<00:00, 3225275.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 5281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.1\n",
    "COS_SIM_THRESHOLD = 0.8\n",
    "pairs_18 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_18 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_18.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_18)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:05<00:00, 3183460.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.1\n",
    "COS_SIM_THRESHOLD = 0.9\n",
    "pairs_19 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_19 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_19.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_19)}\")\n",
    "\n",
    "with open(f'pairs/{category}_1_9.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_19, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17017658/17017658 [00:05<00:00, 3054122.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.05\n",
    "COS_SIM_THRESHOLD = 0.9\n",
    "pairs_59 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_59 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_59.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_59)}\")\n",
    "\n",
    "with open(f'pairs/{category}_5_9.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_59, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats pairs distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_27:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "len(item_cnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411/411 [00:00<00:00, 1711.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5401, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.5401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama 0.058268998046239646\n",
      "Bili 0.0660340280704983\n",
      "Amazon 0.06048952357472825\n"
     ]
    }
   ],
   "source": [
    "print('Alabama', 0.1 * 1 / (exp(0.5401)))\n",
    "print('Bili', 0.1 * 1 / (exp(0.4150)))\n",
    "print('Amazon', 0.1 * 1 / (exp(0.5027)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama -0.1623374063444089\n",
      "Bili -0.11370397114525957\n",
      "Amazon -0.14539919683746585\n"
     ]
    }
   ],
   "source": [
    "print('Alabama', 0.1 * 1 / (log(0.5401)))\n",
    "print('Bili', 0.1 * 1 / (log(0.4150)))\n",
    "print('Amazon', 0.1 * 1 / (log(0.5027)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017999999999999947"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05-20*(0.54-0.5) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.326672684688674e-17"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05-20*(0.55-0.5) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02505971059561011"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01+0.05*exp(-30*(0.04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010336897349954273"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01+0.05*exp(-50*(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02204776847648807"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01+0.04*exp(-30*(0.54-0.5)) # k=1 when x <0.5, k>30 when x > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0154134113294645"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01+0.04*exp(-50*(0.54-0.5)) # k=1 when x <0.5, k>30 when x > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0467404913760583"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01+0.04*exp(1*(0.415-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010269517879963419"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01+0.04*exp(-50*(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046564559591524994"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01+0.04*exp((0.4102-0.5)) # k=1 when x <0.5, k>30 when x > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecticut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Connecticut'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11502506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11502506/11502506 [00:03<00:00, 3352513.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.7\n",
    "pairs_27 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_27 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_27.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_27)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_27, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11502506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11502506/11502506 [00:03<00:00, 3349609.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 738\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.65\n",
    "pairs_265 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_265 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_265.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_265)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_265, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:00<00:00, 3560.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4102, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_265:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.4102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mississippi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Mississippi'\n",
    "co_occurrence = load_npz(f'co_occurrence/{category}.npz')\n",
    "co_occurrence = co_occurrence.tocoo()\n",
    "sim = pickle.load(open(f'cos_sim_of_co_occurence/{category}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5374918/5374918 [00:01<00:00, 2879098.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pairs: 5981\n"
     ]
    }
   ],
   "source": [
    "CO_OCCURENCE_THRESHOLD = 0.2\n",
    "COS_SIM_THRESHOLD = 0.7\n",
    "pairs_27 = set()\n",
    "for i in tqdm(range(len(sim))):\n",
    "    if co_occurrence.data[i] > CO_OCCURENCE_THRESHOLD and sim[i] > COS_SIM_THRESHOLD and \\\n",
    "        (co_occurrence.col[i], co_occurrence.row[i]) not in pairs_27 and \\\n",
    "        (co_occurrence.row[i] != co_occurrence.col[i]):\n",
    "        pairs_27.add((co_occurrence.row[i], co_occurrence.col[i]))\n",
    "print(f\"Length of pairs: {len(pairs_27)}\")\n",
    "\n",
    "with open(f'pairs/{category}.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs_27, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2201/2201 [00:01<00:00, 2063.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6108, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "item_cnt = defaultdict(int)\n",
    "for i, j in pairs_27:\n",
    "    item_cnt[i] += 1\n",
    "    item_cnt[j] += 1\n",
    "\n",
    "all_items = torch.tensor(list(item_cnt.keys()))\n",
    "\n",
    "guide_model_text_embedding = torch.load(f'guide_model_text_embeddings/{category}.pt')\n",
    "guide_model_text_embedding = guide_model_text_embedding.cuda()\n",
    "\n",
    "sim = 0\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(all_items))):\n",
    "    item_i = all_items[i].unsqueeze(-1).cuda()\n",
    "    emb_i = guide_model_text_embedding(item_i)\n",
    "    emb_i = torch.nn.functional.normalize(emb_i, p=2, dim=1)\n",
    "    item_j = all_items[i + 1:]\n",
    "    for start in range(0, len(item_j), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(all_items))\n",
    "        batch_item_j = item_j[start:end].cuda()\n",
    "        emb_j = guide_model_text_embedding(batch_item_j)\n",
    "        emb_j = torch.nn.functional.normalize(emb_j, p=2, dim=1)\n",
    "        sim += (emb_i * emb_j).sum()\n",
    "        cnt += end - start\n",
    "\n",
    "avg_sim = sim / cnt\n",
    "avg_sim # 0.6108"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
